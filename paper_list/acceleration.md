# Acceleration
Acceleration for LLM training and inference.

## Papers
- **High-throughput Generative Inference of Large Language Models with a single GPU** (2023-02) Ying Sheng et al. [Paper](https://github.com/FMInference/FlexGen/blob/main/docs/paper.pdf) | [Github](https://github.com/FMInference/FlexGen)
## Useful Resources
