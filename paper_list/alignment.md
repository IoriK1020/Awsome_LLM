# Alignment

## Papers

### 2023
- (2023-05) **RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs** [paper](https://arxiv.org/abs/2305.08844)

- (2023-05) **Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision** [paper](https://arxiv.org/abs/2305.03047)

- (2023-05) **Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback** [paper](https://arxiv.org/abs/2305.10142)

- (2023-04) **Fundamental Limitations of Alignment in Large Language Models** [paper](https://arxiv.org/abs/2304.11082)

## Useful Resources
